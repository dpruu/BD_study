# 예상 문제

빅데이터의 특징 5V

> Volume(크기),  Velocity(속도),  Variety(다양성), Veracity(정확성), Value(가치)



스키마

> DB의 구조와 제약조건에 관한 전반적인 명세를 의미



비정형데이터

> 정해진 규칙이 없어서 값의 의미를 쉽게 파악할 수 없는 데이터, 흔히 텍스트, 음성, 영상과 같은 데이터
>
> ※ 정형 데이터 : DB에 정해진 규칙에 맞게 데이터를 들어간 데이터 중 수치 만으로 의미 파악이 쉬운 데이터들을 통상적으로 말한다.
>
> ※ 반정형 데이터 : HTML, XML과 같은 스키마를 가지고 있는 형태



 NoSQL

> 빅데이터 저장 기술로 RDBMS와 다른 DBMS를 지칭하기 위한 용어, 고정된 테이블 스키마가 필요 없으며, JOIN 연산을 사용할 수 없는 수평적 확장 가능한 DBMS



PCA (주성분 분석)

> 변수를 공분산 행렬이나 상관행렬을 이용해 원래 데이터 특징을 잘 설명해주는 성분을 추출하기 위해 고차원 공간의 표본들을 선형 연관성이 없는 저차원의 공간으로 변환하는 기법



다차원 척도법

> 개체들 사이의 유사성, 비유사성을 측정해 2,3차원 공간상에 점으로 표현해 개체들 사이의 집단화를 시각적으로 표현하는 분석 방법



웹 크롤링

> 인터넷상에서 제공되는 다양한 웹 사이트로부터 소셜 네스워크 정보, 뉴스, 게시판 등의 웹 문서 및 콘텐츠를 프로그램을 이용해 자동화된 방법으로 수집하는 작업



CNN

> Convolution Neural Network의 약자, 이미지의 공간 정보를 유지한 상태로 학습이 가능한 모델
>
> ※ 딥러닝 : 기계학습의 한 분야로 계층구조로 이루어진 인공신경망의 내부계층이 여러 단계로 이루어진 구조
>
> ※ RNN : 유닛간의 연결이 순환적 구조를 갖는 인공 신경망, 내부 메모리를 이용해 시퀸스 형태의 입력 처리 가능 ex) 음성, 텍스트
>
> ※ LSTM : Long Short-Term Memory, RNN의 한 종류로 RNN과 비교하여 긴 시퀸스의 입력을 처리하는데 탁월하다.



결정계수

> 회귀 모형의 평가 방법, 회귀제곱합을 총제곱합의 값으로 나눈 것, 종속변수의 분산 중 독립변수로 설명되는 비율을 의미
>
> 회귀식이 얼마나 정확한지를 나타내는 숫자
>
> ※ 상관 계수 : 두 변수 사이의 통계적 관계를 표현하기 위해 수치
>
> - 1종 오류 : 가설이 참이지만 표본의 오차로 인해 채택하지 않는 오류
> - 2종 오류 :  가설이 거짓이지만 표본의 오차로 인해 채택하는 경우 



역전파

> 예측값의 정확도를 높이기 위해 출력값과 실제 예측하고자 하는 값ㅇ르 비교하여 가중치를 변경하는 작업
>
> ※ Vanishing Gradient : 학습 과정에서 기울기가 작아지는 방향으로 업데이트를 반복하던 중 시그모이드와 같은 활성화 함수는 미분값이 작아지기 때문에 실제 입력값에 비해 은닉층이나, 출력층의 값이 작게 나온다. 이 과정에서 작아진 기울기는 학습 효율을 저하시킨다.



의사결정나무

> 데이터의 속성들로 패턴을 찾아 분류 과제를 수행할 수 있도록 하는 지도학습 머신러닝 모델
>
> - 루트 노드 : 나무의 시작 노드
> - 부모 노드 : 자식 노드의 상위 노드
>
> - 자식 노드 : 상위 노드에서 분리된 하위 노드
> - 가지 : 하나의 노드로 부터 연결된 노드
> - 깊이 : 노드의 분리 층 수
> - 끝 노드 : 각 가지 끝에 위치한 노드
> - 정지규칙 : 더 이상 분리가 일어나지 않고 현재의 마디가 끝마디가 되도록 하는 여러가지 규칙
>
> ※ CART : 지니 지수(Gini Index) 또는 분산의 감소량을 사용하여 나무의 가지를 이진(Binary) 분리한다. (범주형 변수에 대해서는 지니 지수를 사용하고, 연속형 변수에 대해서는 분산의 감소량을 사용한다.)



하둡

> 방대한 데이터를 저장, 구문 분석하고 구성요소를 처리하기 위한 오픈 소스 프레임워크
>
> ※ 스쿱 : 커넥터를 사용해 관계형 데이터베이스와 하둡간 데이터를 전송하는 기술 
>
> ※ Chukwa : 대규모 분산 시스템 모니터링을 위해 에이전트와 컬렉터 구성을 통해 데이터 수집, 수집된 데이터를 하둡 파일 시스템에 저장하는 기능을 제공하는 데이터 수집 기술



언더피팅

> 데이터가 너무 적거나 학습이 제대로 이루어지지 않은 상태
>
> ※ 오버피팅 : 샘플 데이터만 가지고 학습 결과 학습 데이터에만 정확하게 학습된 상태
>
> - Drop out : 오버피팅을 방지하기 위해 학습과정에서 일부 뉴런을 생략하는 기법



전진제거법

> 아무 변수가 없는 영모형에서 하나씩 변수를 추가해가며 모형을 선택
>
> ※ 후진제거법 : 회귀모형 변수 선택시 도움이 되지 않는 변수들을 하나씩 제거하는 방법



결측치

> 누락된 데이터



앙상블

> 여러개의 분류기를 생성, 예측을 결합해 보다 정확한 예측을 도출하는 기법
>
> ※ 부스팅 : 약한 학습기들을 순차적으로 여러개 결합해 예측 혹은 분류 성능을 높이는 알고리즘, 분류가 잘못된 데이터에 더 큰 가중을 줘 표본을 추출하는 앙상블 모형



F1 score

> 정밀도와 재현율(민감도)의 조화 평균,  2 × ((정밀도×재현율) / (정밀도+재현율) )
>
> ※ 민감도 : 실제 긍정인 범주에서 긍정으로 예측한 비율
>
> ※ 정밀도 : 긍정으로 예측한 것 중 실제 긍정인 것
>
> ※ 특이도 : 실제 부정인 범주에서 부정으로 예측한 비율
>
> ※ ROC Curve : x축을 FPR(1-특이도), y축을 TPR



강화학습

> 경험을 통해 보상을 주면 학습하는 기계학습
>
> ※ 비지도 학습 : 목표값 없이 데이터가 어떻게 구성되었는지를 알아내는 기계 학습
>
> - K-means Clustering : 주어진 데이터를 k개의 클러스터로 묶는 알고리즘



경사하강법

> 기본 개념은 함수의 기울기를 구하고 경사의 절댓값이 낮은 쪽으로 계속 이동시켜 극값에 이를 때까지 반복시키는 것이다.



IQR

> Interquartile range의 약자 q3 - q1을 의미 



Threshold

> 임계값, 이분법으로 분류시 분류 기준



감성분석

> 문장에서 사용된 단어의 긍정, 부정여부에 따라 얼마나 긍정적인 단어가 많은지 소스를 부여해 긍정문장인지 평가하는 데이터 마이닝의 종류
>
> ※ 데이터 마이닝 : 대규모로 저장된 데이터 안에서 체계적이고 자동적으로 통계적 규칙이나 패턴을 분석하여 가치있는 정보를 추출하는 과정
>
> ※ Apiriori : 연관규칙의 대표적인 형태, 데이터들에 대한 발생빈도를 기반으로 각 데이터 간의 연관관계를 밝히기 위한 방법



장바구니 분석

> 고객들의 상품 구매 데이터를 이용해 품목 간의 연관성을 알아본다는 의미, 항목들 관계를 If-Then 형식으로 찾아나가는 분석 방법
>
> - 신뢰도 : X를 포함하는 거래 내역 중, Y가 포함된 비율이 높아야 한다.
> - 지지도 : X,Y를 동시에 포함하는 비율이 높아야 한다.
> - 향상도 : 지지도와 신뢰도만으로 충분한가



사회연결망분석

> 사회 연결망 데이터를 활용해 사회 연결망과 사회 구조등을 사회과학적으로 분석하는 하나의 방식
>
> ※ API  : 컴퓨터나 컴퓨터 프로그램 사이의 연결, 일종의 소프트웨어 인터페이스이며 다른 종류의 소프트웨어에 서비스를 제공한다.



퍼셉트론

> 초기 형태의 인공 신경망으로 다수의 입력으로 하나의 결과를 내보내는 알고리즘



활성화함수

> 입력된 데이터의 가중 합을 출력 신호로 변환하는 함수. 인공 신경망에서 이전 레이어에 대한 가중 합의 크기에 따라 활성 여부 결정
>
> - 계단 함수 : 0,1의 이산적인 값을 출력, 딥러닝의 활성화 함수로는 부적절
> - 시그모이드 : 유한한 구간 사이의 값 반환. 정의역의 절대값이 클수록 미분 값은 0으로 수렴해 Gradient Vanishing이 발생 가능
> - ReLu : 0보다 작으면 0, 클 경우 입력 값 그대로 출력
> - 소프트맥스 : 출력 값이 0 ~ 1 사이로 정규화, 총합이 항상 1이 되는 특성을 갖는다. 다중 클래스를 분류하는 목적으로 사용



손실함수

> Cost Function으로 불리며 예측 값과 실제 값과의 차이를 표현하는 지표
>
> ※ 오차 계산법
>
> - MAE : 평균절대오차, 오차의 절댓값을 더하고 개수로 평균을 낸 값
> - MSE : 오차 제곱합의 평균
> - RMSE : MSE에 루트를 씌운 값
>
> ※ Optimizer : 손실 함수를 줄여나가는 알고리즘
>
> - 경사 하강법 : 경사를 따라 내려가며 가중치 업데이트
> - 배치 경사 하강법 : 배치를 전체 데이터로 두는 방법
> - SGD : 랜덤으로 선택한 하나의 데이터에 대해서만 계산하는 방법
> - 모멘텀 : 계산된 접선의 기울기에 한 시점전의 접선의 기울기 값을 일정한 비율만큼 반영
> - 아담 : RMSprop와 모멘텀을 합친 방법, 방향과 학습률 두 가지를 모두 잡기 위한 방법



파생변수

> 기존의 변수를 조합해 만든 새로운 변수
>
> ※ 독립 변수 : 다른 변수의 변화와 관계없이 독립적으로 변하고, 다른 변수의 값을 결정하는 변수
>
> ※ 종속 변수 : 독립 변수에 의해 영향을 받는 변수



다중공선성

> 독립변수들 간 강한 상관관계를 나타나서, 회귀분석의 전제가정인 독립변수들 간에 상관관계가 높으면 안된다는 조건을 위배하는 경우를 의미하는 용어



K-fold cross validation

> K개의 fold를 만들어 진행하는 교차 검증, 데이터 개수가 적은 데이터 셋에 대해 정확도 향상 가능



실루엣계수

> 각 데이터 포인트와 주위 데이터 포인터들과의 거리 계산을 통해 값을 구하며, 군집 안에 있는 데이터들은 잘 모여있는지, 군집끼리는 서로 잘 구분되는지 클러스터링을 평가하는 척도



나이브베이즈분류

> 지도학습의 일종, 사후확률의 계산시 조건부 독립을 사정하여 계산을 단순화한 방법, 사후확률이 큰 집단으로 새로운 데이터를 분류하는 모델
>
> ex) 스팸 메일 분류
>
> ※ SVM : 패턴 인식, 자료 분석을 위한 지도 학습 모형, 주어진 데이터 집합을 바탕으로 새로운 데이터가 어느 카테고리에 속할지 판단하는 비 확률적 이진 선형 분류 모델



BMU

> SOM에서 입력층과 제일 가까운 뉴런(Best Matching Unit)
>
> ※ SOM(Self Organizing Map) : 자기조직화지도 알고리즘, 비지도 신경망으로 고차워느이 데이터를 이해하기 쉬운 저차원의 뉴련으로 정렬해 지도의 형태로 형상화함



배깅

> bootstrap aggregating의 준말로 앙상블 기법 중 하나, 데이터에 대해 여러개의 붓스트랩 자료를 생성하고 각 자료를 모델링 한 후 결합해 최종 예측 모형을 산출하는 방법
>
> ex) 랜덤 포레스트 모델
>
> ※ 부트스트랩 : 주어진 자료에서  단순랜덤 복원추출 방법을 활용하여 동일한 크기의 표본을 여러개 생성하는 샘플링 방법



ARIMA 모형

> 대표적인 통계적 시계열 예측 모형으로, 현재값을 과거값과 과거 예측오차를 통해 설명한다.
>
> ※ 추세선 : 일정 기간 동안 한쪽 방향으로 움직이는 경향을 연결한 선
>
> ※ 시계열 분석 : 일정한 시간 간격으로 표시된 자료의 특성을 분석해 미래를 예측하는 방법
>
> ※ 분해 시계열 : 시계열에 영향을 주는 일반적인 요인을 시계열에서 분리해 분석하는 방법
>
> - 계절 요인 : 분해 시계열 분석에서 고정된 주기를 가지고 자료가 변화하는 요인
> - 순환 요인 : 불규칙적이며 반복적인 중기 변동 요인
> - 고정 요인 : 요인이 가지는 수준자체가 교유의 의미를 가지고 있어 값의 차이 비교 



차원의 저주 

> 데이터 학습을 위해 차원이 증가하면서 학습데이터 수가 차원의 수보다 적어져 성능이 저하되는 현상



k-익명성

> 프라이버시보호모델 중 특정인임을 추론할 수 있는지 여부를 검토, 일정 확률수준 이상 비식별되도록 하는 기법
>
> ※ L-다양성 : 각 블록이 적어도 L개의 다양한 민감정보를 가지고 있어야 한다.
>
> ※ T-접근성 : 데이터 집합에서 구별되지 않는 레코드들의 민감한 정보의 분포와, 전체 데이터의 민감한 정보의 분포의 차이를 t이하로 프라이버시를 보호하는 모델



Kafka

> Pub-Sub 모델의 메시지 큐. 분산환경 특화되어있는 특징을 갖는다.



데이터 3법

> 개인정보보호법, 정보통신망법, 신용정보법







